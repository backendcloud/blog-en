<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Openstack operation and maintenance records (1) - English version of the website https://www.backendcloud.cn/</title>
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../style.css">
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');
                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }
                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../SUMMARY.html"><strong aria-hidden="true">1.</strong> Catalog: Openstack</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../openstack/openstack-op-1.html" class="active"><strong aria-hidden="true">1.1.</strong> Openstack operation and maintenance records (1)</a></li><li class="chapter-item expanded "><a href="../openstack/openstack-local-yum.html"><strong aria-hidden="true">1.2.</strong> Openstack Pike local yum source construction</a></li><li class="chapter-item expanded "><a href="../openstack/cpu-binding.html"><strong aria-hidden="true">1.3.</strong> CPU binding</a></li><li class="chapter-item expanded "><a href="../openstack/resize-fail.html"><strong aria-hidden="true">1.4.</strong> Investigation of the cause of resize failure</a></li><li class="chapter-item expanded "><a href="../openstack/mount-cloud-disk.html"><strong aria-hidden="true">1.5.</strong> Mount cloud disk</a></li><li class="chapter-item expanded "><a href="../openstack/ocata-nova-evacuate-bug.html"><strong aria-hidden="true">1.6.</strong> Ocata nova evacuate bug</a></li><li class="chapter-item expanded "><a href="../openstack/compute-node-ha.html"><strong aria-hidden="true">1.7.</strong> compute node ha mainstream open source implementation</a></li><li class="chapter-item expanded "><a href="../openstack/collectd-influxdb.html"><strong aria-hidden="true">1.8.</strong> Deployment and usage of Collectd and InfluxDB</a></li><li class="chapter-item expanded "><a href="../openstack/live-migration-local.html"><strong aria-hidden="true">1.9.</strong> Live Migration on Local Storage</a></li><li class="chapter-item expanded "><a href="../openstack/fast-evacuation.html"><strong aria-hidden="true">1.10.</strong> Add fast evacuation function to VM HA procedure</a></li><li class="chapter-item expanded "><a href="../openstack/vm-activation-failure.html"><strong aria-hidden="true">1.11.</strong> Windows virtual machine activation failure problem</a></li></ol></li><li class="chapter-item expanded "><a href="../SUMMARY.html"><strong aria-hidden="true">2.</strong> Catalog: Tools</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../tools/xshell-skill.html"><strong aria-hidden="true">2.1.</strong> Some Skills of using xshell tools</a></li></ol></li><li class="chapter-item expanded "><a href="../SUMMARY.html"><strong aria-hidden="true">3.</strong> Catalog: Point of view</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../tools/gerrit-install.html"><strong aria-hidden="true">3.1.</strong> gerrit install</a></li><li class="chapter-item expanded "><a href="../point-of-view/huawei-and-operators.html"><strong aria-hidden="true">3.2.</strong> Huawei and telecom operators</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">English version of the website https://www.backendcloud.cn/</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <p>release time :2018-08-26 18:38</p>
<h1 id="troubleshooting-process"><a class="header" href="#troubleshooting-process">Troubleshooting process</a></h1>
<ul>
<li>First determine the resource ID of the fault, and determine the component where the fault occurred</li>
<li>Check the log of the corresponding component, search according to the fault resource ID, and find the corresponding ERROR log</li>
<li>If the ERROR log points the problem to other components, then according to the resource ID, time, req-id and other information in the ERROR log, other components continue to search for the problem until the root cause of the problem is found.</li>
<li>If no ERROR is found in the log, it may be that the network is not connected, causing the request to fail to reach the API. At this time, you need to check the connectivity with the API (if you use VIP, you need to check the connectivity with the VIP and the connectivity of the real IP separately. ).</li>
<li>If the corresponding request can be found in the API, but the conductor/scheduler/compute does not find the corresponding log, it may be that the MQ is faulty.</li>
<li>If the component has not refreshed any logs for a long time, the component process may hang or be in a dead state. You can try to restart the service, or open Debug first and then restart the service. </li>
</ul>
<h1 id="create-vm-error"><a class="header" href="#create-vm-error">create vm error</a></h1>
<pre><code>[root@EXTENV-194-18-2-16 nova]# cat nova-compute.log | grep 620cd801-8849-481a-80e0-2980b6c8dba6
2018-08-23 15:23:36.136 3558 INFO nova.compute.resource_tracker [req-f76d5408-00f8-4a67-854e-ad3da2098811 - - - - -] Instance 620cd801-8849-481a-80e0-2980b6c8dba6 has allocations against this compute host but is not found in the database.
</code></pre>
<p>Analysis: It feels that the information database of node is out of sync</p>
<p>nova show error vm, package cell error</p>
<pre><code>#### Each time a computing node is added, the control node needs to execute:
# su -s /bin/sh -c &quot;nova-manage cell_v2 discover_hosts --verbose&quot; nova
</code></pre>
<p>problem solved.</p>
<h1 id="the-neutron-service-is-good-and-the-command-line-creates-a-network-to-view-the-network-normally-but-the-dashboard-cannot-view-network-related-pages"><a class="header" href="#the-neutron-service-is-good-and-the-command-line-creates-a-network-to-view-the-network-normally-but-the-dashboard-cannot-view-network-related-pages">The neutron service is good, and the command line creates a network to view the network normally, but the dashboard cannot view network-related pages</a></h1>
<p>The dashboard network page reports an error Invalid service catalog service: network</p>
<p>Analysis: It should be that Keystone is not properly configured. As a result, no relevant Catalog information was found.</p>
<pre><code>[root@EXTENV-194-18-2-11 ~]# openstack catalog list
+-----------+-----------+-----------------------------------------------+
| Name      | Type      | Endpoints                                     |
+-----------+-----------+-----------------------------------------------+
| placement | placement | RegionOne                                     |
|           |           |   internal: http://nova-ha-vip:8778           |
|           |           | RegionOne                                     |
|           |           |   admin: http://nova-ha-vip:8778              |
|           |           | RegionOne                                     |
|           |           |   public: http://nova-ha-vip:8778             |
|           |           |                                               |
| keystone  | identity  | RegionOne                                     |
|           |           |   public: http://keystone-ha-vip:5000/v3/     |
|           |           | RegionOne                                     |
|           |           |   internal: http://keystone-ha-vip:35357/v3/  |
|           |           | RegionOne                                     |
|           |           |   admin: http://keystone-ha-vip:35357/v3/     |
|           |           |                                               |
| glance    | image     | RegionOne                                     |
|           |           |   admin: http://glance-ha-vip:9292            |
|           |           | RegionOne                                     |
|           |           |   internal: http://glance-ha-vip:9292         |
|           |           | RegionOne                                     |
|           |           |   public: http://glance-ha-vip:9292           |
|           |           |                                               |
| nova      | compute   | RegionOne                                     |
|           |           |   public: http://nova-ha-vip:8774/v2.1        |
|           |           | RegionOne                                     |
|           |           |   admin: http://nova-ha-vip:8774/v2.1         |
|           |           | RegionOne                                     |
|           |           |   internal: http://nova-ha-vip:8774/v2.1      |
|           |           |                                               |
| neutron   | network   |                                               |
| neutron   | network   | RegionOne                                     |
|           |           |   public: http://neutron-server-ha-vip:9696   |
|           |           | RegionOne                                     |
|           |           |   admin: http://neutron-server-ha-vip:9696    |
|           |           | RegionOne                                     |
|           |           |   internal: http://neutron-server-ha-vip:9696 |
|           |           |                                               |
+-----------+-----------+-----------------------------------------------+
</code></pre>
<p>So just delete the first piece of data without url, but found that there is only openstack catalog list, no openstack catalog delete command. Later, I checked the keystone configuration file keystone.conf and found the following configuration
see [catalog]</p>
<p>From the configuration file and some information, it can be seen that the catalog is the data read from mysql, and then the dirty data is found in the service table in the keystone library of mysql, and then I know to use openstack service delete to delete the 'dirty data', the problem is solved.</p>
<pre><code>MariaDB [keystone]&gt; select * from service;
+----------------------------------+-----------+---------+-------------------------------------------------------------+
| id                               | type      | enabled | extra                                                       |
+----------------------------------+-----------+---------+-------------------------------------------------------------+
| 520f6bf8564240be9678c4ef25305cad | placement |       1 | {&quot;description&quot;: &quot;OpenStack Placement&quot;, &quot;name&quot;: &quot;placement&quot;} |
| 960580852a594c078e68fe3683e35db5 | identity  |       1 | {&quot;name&quot;: &quot;keystone&quot;}                                        |
| 98ed18fcd8104732919bb5869a5a6dc2 | image     |       1 | {&quot;description&quot;: &quot;OpenStack Image&quot;, &quot;name&quot;: &quot;glance&quot;}        |
| abef1b9469d94d3ab9f27c8ed72a5a48 | compute   |       1 | {&quot;description&quot;: &quot;OpenStack Compute&quot;, &quot;name&quot;: &quot;nova&quot;}        |
| e37085e8fb2a49c0921c2d24f5e4f9b5 | network   |       1 | {&quot;description&quot;: &quot;OpenStack Networking&quot;, &quot;name&quot;: &quot;neutron&quot;}  |
| f1b661407ce04f79bc24605fa59bb74c | network   |       1 | {&quot;description&quot;: &quot;OpenStack Networking&quot;, &quot;name&quot;: &quot;neutron&quot;}  |
+----------------------------------+-----------+---------+-------------------------------------------------------------+
6 rows in set (0.00 sec)

MariaDB [keystone]&gt; select * from endpoint;
+----------------------------------+--------------------+-----------+----------------------------------+-----------------------------------+-------+---------+-----------+
| id                               | legacy_endpoint_id | interface | service_id                       | url                               | extra | enabled | region_id |
+----------------------------------+--------------------+-----------+----------------------------------+-----------------------------------+-------+---------+-----------+
| 142cb619cd2242828b0c9394d5baaea1 | NULL               | public    | f1b661407ce04f79bc24605fa59bb74c | http://neutron-server-ha-vip:9696 | {}    |       1 | RegionOne |
| 2252d3ef840b4c5aa1184ebe8d6094f1 | NULL               | public    | abef1b9469d94d3ab9f27c8ed72a5a48 | http://nova-ha-vip:8774/v2.1      | {}    |       1 | RegionOne |
| 476654c6e7dd4d22b290de451e3afda0 | NULL               | admin     | abef1b9469d94d3ab9f27c8ed72a5a48 | http://nova-ha-vip:8774/v2.1      | {}    |       1 | RegionOne |
| 562a5d5443af4dfab6760204d0adf3bf | NULL               | internal  | 520f6bf8564240be9678c4ef25305cad | http://nova-ha-vip:8778           | {}    |       1 | RegionOne |
| 58bd5f09811a4ebcb62a4b51fb7ae444 | NULL               | admin     | f1b661407ce04f79bc24605fa59bb74c | http://neutron-server-ha-vip:9696 | {}    |       1 | RegionOne |
| 600811f8ccaf42669d4d83b897af3933 | NULL               | admin     | 520f6bf8564240be9678c4ef25305cad | http://nova-ha-vip:8778           | {}    |       1 | RegionOne |
| 80683f619efb41dcbb6796ea04f16159 | NULL               | internal  | f1b661407ce04f79bc24605fa59bb74c | http://neutron-server-ha-vip:9696 | {}    |       1 | RegionOne |
| 8e0a684607294a729f87d7d8b1a639ca | NULL               | public    | 520f6bf8564240be9678c4ef25305cad | http://nova-ha-vip:8778           | {}    |       1 | RegionOne |
| 9ef0f18d891e45608ffc41985dc6afa6 | NULL               | public    | 960580852a594c078e68fe3683e35db5 | http://keystone-ha-vip:5000/v3/   | {}    |       1 | RegionOne |
| a0b10cb04a5b4ca3859aaf2ea4ca2a3b | NULL               | admin     | 98ed18fcd8104732919bb5869a5a6dc2 | http://glance-ha-vip:9292         | {}    |       1 | RegionOne |
| c53979becccc44f1813e9f50a619af7e | NULL               | internal  | 960580852a594c078e68fe3683e35db5 | http://keystone-ha-vip:35357/v3/  | {}    |       1 | RegionOne |
| dadbb8dc218245bbba8c9a34237413ec | NULL               | internal  | 98ed18fcd8104732919bb5869a5a6dc2 | http://glance-ha-vip:9292         | {}    |       1 | RegionOne |
| f4034b8c086a451caed52ac51a761fb0 | NULL               | public    | 98ed18fcd8104732919bb5869a5a6dc2 | http://glance-ha-vip:9292         | {}    |       1 | RegionOne |
| fc150884825544baaf4912f14e76f51a | NULL               | internal  | abef1b9469d94d3ab9f27c8ed72a5a48 | http://nova-ha-vip:8774/v2.1      | {}    |       1 | RegionOne |
| fc7132052063438895674fd7b840db68 | NULL               | admin     | 960580852a594c078e68fe3683e35db5 | http://keystone-ha-vip:35357/v3/  | {}    |       1 | RegionOne |
+----------------------------------+--------------------+-----------+----------------------------------+-----------------------------------+-------+---------+-----------+
15 rows in set (0.00 sec)

[root@EXTENV-194-18-2-11 ~]#  openstack service list
+----------------------------------+-----------+-----------+
| ID                               | Name      | Type      |
+----------------------------------+-----------+-----------+
| 520f6bf8564240be9678c4ef25305cad | placement | placement |
| 960580852a594c078e68fe3683e35db5 | keystone  | identity  |
| 98ed18fcd8104732919bb5869a5a6dc2 | glance    | image     |
| abef1b9469d94d3ab9f27c8ed72a5a48 | nova      | compute   |
| e37085e8fb2a49c0921c2d24f5e4f9b5 | neutron   | network   |
| f1b661407ce04f79bc24605fa59bb74c | neutron   | network   |
+----------------------------------+-----------+-----------+
[root@EXTENV-194-18-2-11 ~]#  openstack service delete e37085e8fb2a49c0921c2d24f5e4f9b5
[root@EXTENV-194-18-2-11 ~]# systemctl restart httpd.service memcached.service
</code></pre>
<h1 id="when-viewing-the-image-named-in-chinese-an-error-is-reported"><a class="header" href="#when-viewing-the-image-named-in-chinese-an-error-is-reported">When viewing the image named in Chinese, an error is reported</a></h1>
<pre><code>[root@NFJD-TESTVM-CORE-API-1 ~]# glance image-list
'ascii' codec can't encode character u'\u5982' in position 1242: ordinal not in range(128)
</code></pre>
<p>Analysis: The image name is named in Chinese.</p>
<p>Add export LC_ALL=zh_CN.UTF-8</p>
<p>to /etc/profile</p>
<p>At the same time, pay attention to whether there is export LC_ALL=C in the source file</p>
<h1 id="vm-build-failed"><a class="header" href="#vm-build-failed">vm build failed</a></h1>
<pre><code>2017-05-25 11:01:29.577 21880 TRACE nova.compute.manager [instance: 2c5a8e62-62d0-430d-8747-795350bb6939] ProcessExecutionError: Unexpected error while running command.
2017-05-25 11:01:29.577 21880 TRACE nova.compute.manager [instance: 2c5a8e62-62d0-430d-8747-795350bb6939] Command: qemu-img convert -O raw /var/lib/nova/instances/_base/f5797db00aacfbe240bbfb0f53c2da80e4be6dfc.part /var/lib/nova/instances/_base/f5797db00aacfbe240bbfb0f53c2da80e4be6dfc.converted
2017-05-25 11:01:29.577 21880 TRACE nova.compute.manager [instance: 2c5a8e62-62d0-430d-8747-795350bb6939] Exit code: 1
2017-05-25 11:01:29.577 21880 TRACE nova.compute.manager [instance: 2c5a8e62-62d0-430d-8747-795350bb6939] Stdout: u''
2017-05-25 11:01:29.577 21880 TRACE nova.compute.manager [instance: 2c5a8e62-62d0-430d-8747-795350bb6939] Stderr: u'qemu-img: error while writing sector 1569792: No space left on device\n'
2017-05-25 11:01:29.577 21880 TRACE nova.compute.manager [instance: 2c5a8e62-62d0-430d-8747-795350bb6939]
2017-05-25 11:01:29.580 21880 INFO nova.compute.manager [req-9fa74abf-bcc1-4b7e-aaef-2e17b593a356 6aa5df16b47442c58efde791abd60497 66458b9ead64409fb9d2e0f2c6d67d39 - - -] [instance: 2c5a8e62-62d0-430d-8747-795350bb6939] Terminating instance


# df -h
</code></pre>
<p>Found that the disk is running out</p>
<p>Countermeasure: clean up the disk</p>
<h1 id="evacuation-failed"><a class="header" href="#evacuation-failed">Evacuation failed</a></h1>
<p>Executed a nova evacuation command, but the evacuation failed, nova show reported this error: the state of the shared storage is wrong. That is, the nova instances directory does not have shared storage. If the ceph shared storage is not configured, the shared storage parameters are still included when the nova evacuate command is executed.</p>
<pre><code>| fault                                | {&quot;message&quot;: &quot;Invalid state of instance files on shared storage&quot;, &quot;code&quot;: 500, &quot;details&quot;: &quot;  File \&quot;/usr/lib/python2.7/site-packages/nova/compute/manager.py\&quot;, line 354, in decorated_function |
|                                      |     return function(self, context, *args, **kwargs)                                                                                                                                            |
|                                      |   File \&quot;/usr/lib/python2.7/site-packages/nova/compute/manager.py\&quot;, line 3031, in rebuild_instance                                                                                            |
|                                      |     _(\&quot;Invalid state of instance files on shared\&quot;                                                                                                                                            |
|                                      | &quot;, &quot;created&quot;: &quot;2017-05-17T01:25:17Z&quot;}       
</code></pre>
<h1 id="there-is-a-certain-probability-that-the-console-cannot-be-displayed"><a class="header" href="#there-is-a-certain-probability-that-the-console-cannot-be-displayed">There is a certain probability that the console cannot be displayed</a></h1>
<p>Operation steps: console-virtual machine, click the name of the virtual machine, click [console]</p>
<p>Expected result: display the console page normally</p>
<p>Actual result: There is a certain probability that the page will prompt &quot;Failed to connect to server&quot;, click to open in a new window to open the console page</p>
<p>The configuration problem of the nova control node, the hosts configuration of memcache and rabbitmq in the configuration file is incorrect</p>
<h1 id="on-the-dashboard-interface-use-the-image-centos7-flavor-2-to-create-a-virtual-machine-error-and-the-error-thrown-is-no-host-that-is-no-suitable-scheduling-node-was-found"><a class="header" href="#on-the-dashboard-interface-use-the-image-centos7-flavor-2-to-create-a-virtual-machine-error-and-the-error-thrown-is-no-host-that-is-no-suitable-scheduling-node-was-found">On the dashboard interface, use the image centos7, flavor-2 to create a virtual machine error. And the error thrown is no host, that is, no suitable scheduling node was found.</a></h1>
<p>If the size of the flavor is smaller than the image requirement, an error will be reported.</p>
<p>But once again, the above conditions are met and an error is reported.</p>
<p>It is possible that the flavor was created with illegal extra_specs</p>
<pre><code>OS-FLV-DISABLED:disabled  False
OS-FLV-EXT-DATA:ephemeral   0
disk    20
extra_specs {&quot;xxx&quot;: &quot;123&quot;, &quot;yyy&quot;: &quot;321&quot;}
</code></pre>
<p>The filtering option turns on the ComputeCapabilitiesFilter filter.</p>
<h1 id="import-error"><a class="header" href="#import-error">import error</a></h1>
<p>glance register.log error:</p>
<pre><code>2017-05-08 03:18:55.890 3185 ERROR glance.common.config [-] Unable to load glance-registry-keystone from configuration file /usr/share/glance/glance-registry-dist-paste.ini.
Got: ImportError('No module named simplegeneric',)
</code></pre>
<p>/usr/lib/python2.7/site-packages/simplegeneric.py has no read permission, who changed it</p>
<h1 id="keystone-error"><a class="header" href="#keystone-error">keystone error</a></h1>
<p>Permission denied: AH00072: make_sock: could not bind to address [::]:5000</p>
<pre><code>[root@controller0 ~]# systemctl start httpd.service
Job for httpd.service failed because the control process exited with error code. See &quot;systemctl status httpd.service&quot; and &quot;journalctl -xe&quot; for details.
[root@controller0 ~]# systemctl status httpd.service
● httpd.service - The Apache HTTP Server
Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled)
Active: failed (Result: exit-code) since Sat 2016-05-28 20:22:34 EDT; 11s ago
    Docs: man:httpd(8)
        man:apachectl(8)
Process: 4501 ExecStop=/bin/kill -WINCH ${MAINPID} (code=exited, status=1/FAILURE)
Process: 4499 ExecStart=/usr/sbin/httpd $OPTIONS -DFOREGROUND (code=exited, status=1/FAILURE)
Main PID: 4499 (code=exited, status=1/FAILURE)

May 28 20:22:34 controller0 httpd[4499]: (13)Permission denied: AH00072: make_sock: could not bind to address [::]:5000
May 28 20:22:34 controller0 httpd[4499]: (13)Permission denied: AH00072: make_sock: could not bind to address 0.0.0.0:5000
</code></pre>
<p>It may be a firewall configuration problem or selinux. If there is no problem with the firewall, check selinux</p>
<p>check selinux status:
1 [root@controller0 ~]# getenforce
2 enforcing #If it is not disabled, it means that selinux is running normally</p>
<p>SELINUX=enforcing changed to selinux=distabled</p>
<p>restart reboot</p>
<h1 id="re-scheduled-not-authorized-for-image"><a class="header" href="#re-scheduled-not-authorized-for-image">re-scheduled: Not authorized for image</a></h1>
<p>The CLI reports an error:</p>
<pre><code>| fault                                | {&quot;message&quot;: &quot;Build of instance d5739cf7-9830-47fd-9a75-e9b1cb4bb421 was re-scheduled: Not authorized for image dcd85799-92f6-4294-91ec-48670a218651.&quot;, &quot;code&quot;: 500, &quot;details&quot;: &quot;  File \&quot;/usr/lib/python2.7/site-packages/nova/compute/manager.py\&quot;, line 2258, in _do_build_and_run_instance |
</code></pre>
<p>Logging in to the computing node also reports an error</p>
<pre><code>2017-05-18 15:01:24.867 40639 TRACE nova.compute.manager [instance: d5739cf7-9830-47fd-9a75-e9b1cb4bb421] ImageNotAuthorized: Not authorized for image dcd85799-92f6-4294-91ec-48670a218651.
2017-05-18 15:01:24.867 40639 TRACE nova.compute.manager [instance: d5739cf7-9830-47fd-9a75-e9b1cb4bb421]
</code></pre>
<p>So add</p>
<pre><code>[DEFAULT]
auth_strategy=keyston in /etc/nova/nova.conf
and the missing e
should be:
[DEFAULT]
auth_strategy=keystone
</code></pre>
<h1 id="libvirterror-unsupported-configuration-ide-controllers-are-unsupported-for-this-qemu-binary-or-machine-type"><a class="header" href="#libvirterror-unsupported-configuration-ide-controllers-are-unsupported-for-this-qemu-binary-or-machine-type">libvirtError: unsupported configuration: IDE controllers are unsupported for this QEMU binary or machine type</a></h1>
<pre><code>2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f] Traceback (most recent call last):
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/nova/compute/manager.py&quot;, line 2483, in _build_resources
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     yield resources
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/nova/compute/manager.py&quot;, line 2355, in _build_and_run_instance
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     block_device_info=block_device_info)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py&quot;, line 2704, in spawn
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     block_device_info=block_device_info)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py&quot;, line 4758, in _create_domain_and_network
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     power_on=power_on)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py&quot;, line 4689, in _create_domain
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     LOG.error(err)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/oslo_utils/excutils.py&quot;, line 85, in __exit__
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     six.reraise(self.type_, self.value, self.tb)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py&quot;, line 4679, in _create_domain
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     domain.createWithFlags(launch_flags)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/eventlet/tpool.py&quot;, line 186, in doit
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     result = proxy_call(self._autowrap, f, *args, **kwargs)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/eventlet/tpool.py&quot;, line 144, in proxy_call
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     rv = execute(f, *args, **kwargs)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/eventlet/tpool.py&quot;, line 125, in execute
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     six.reraise(c, e, tb)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib/python2.7/site-packages/eventlet/tpool.py&quot;, line 83, in tworker
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     rv = meth(*args, **kwargs)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]   File &quot;/usr/lib64/python2.7/site-packages/libvirt.py&quot;, line 1065, in createWithFlags
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)
2017-05-18 15:06:09.522 41033 TRACE nova.compute.manager [instance: c348b942-4553-4023-bbcb-296f3b1bf14f] libvirtError: unsupported configuration: IDE controllers are unsupported for this QEMU binary or machine type
</code></pre>
<p>Change the IDE to virtio</p>
<h1 id="qemu-kvm-cirrus-vga-not-available"><a class="header" href="#qemu-kvm-cirrus-vga-not-available">qemu-kvm: Cirrus VGA not available</a></h1>
<pre><code>| fault                                | {&quot;message&quot;: &quot;Build of instance a1feb48a-b5f5-48ab-93a7-838bb46573fb was re-scheduled: internal error: process exited while connecting to monitor: 2017-05-18T10:33:34.222333Z qemu-kvm: Cirrus VGA not available&quot;, &quot;code&quot;: 500, &quot;details&quot;: &quot;  File \&quot;/usr/lib/python2.7/site-packages/nova/compute/manager.py\&quot;, line 2258, in _do_build_and_run_instance |
</code></pre>
<p>Machines with power architecture do not support Cirrus VGA</p>
<h1 id="the-default-route-cannot-be-deleted"><a class="header" href="#the-default-route-cannot-be-deleted">The default route cannot be deleted</a></h1>
<p>There are two services to confirm whether the status is normal. network and NetworkManager</p>
<h1 id="dashboard-access-lag"><a class="header" href="#dashboard-access-lag">dashboard access lag</a></h1>
<p>The reason for locating the dashboard card is that it should be a nova card,</p>
<p>nova freezes because nova cannot establish a connection with memcached,</p>
<p>It is further located that the default maximum number of connections for memcached is 1024, which has reached the maximum number of connections so far.</p>
<p>The solution is to edit /etc/sysconfig/memcached</p>
<p>The parameters are modified to:</p>
<pre><code>PORT=&quot;11211&quot;
USER=&quot;memcached&quot;
MAXCONN=&quot;65536&quot;
CACHESIZE=&quot;1024&quot;
OPTIONS=&quot;&quot;
</code></pre>
<p>restart memcached</p>
<h1 id="task_state-has-been-in-scheduling"><a class="header" href="#task_state-has-been-in-scheduling">task_state has been in scheduling</a></h1>
<p>Nova boot executes a certain node to generate vm, task_state is always in scheduling, vm_state is always in building, it may be that the nova-compute state of the node that is forced to be scheduled is down.</p>
<h1 id="access-denied-for-user-nova-to-database-nova_api"><a class="header" href="#access-denied-for-user-nova-to-database-nova_api">Access denied for user 'nova'@'%' to database 'nova_api'</a></h1>
<p>Initialize the database when initializing the nova_api database</p>
<pre><code>su -s /bin/sh -c &quot;nova-manage api_db sync&quot; nova
</code></pre>
<p>Error:</p>
<pre><code>Access denied for user 'nova'@'%' to database 'nova_api'
</code></pre>
<p>The root user enters the database and executes</p>
<pre><code>&gt; GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' IDENTIFIED BY '2267593eb27be7c414fc';
</code></pre>
<p>solve</p>
<h1 id="all-nodes-have-insufficient-disks-and-return-0-available-hosts"><a class="header" href="#all-nodes-have-insufficient-disks-and-return-0-available-hosts">All nodes have insufficient disks, and return 0 available hosts</a></h1>
<p>Go to the node df -h and find that there is a lot of disk space left. Nova judges the disk space of a node not based on ll, but based on the space occupied by vm and other data.</p>
<p>Such as:</p>
<pre><code>[root@NFJD-PSC-IBMN-SV356 10d31bfa-961d-44ea-b554-7575315a8e2e]# ll -h
total 679M
-rw-rw---- 1 root root  16K Nov 17 17:32 console.log
-rw-r--r-- 1 root root 679M Nov 18 10:07 disk
-rw-r--r-- 1 qemu qemu 422K Nov 17 17:24 disk.config
-rw-r--r-- 1 nova nova  162 Nov 17 17:24 disk.info
-rw-r--r-- 1 nova nova 3.4K Nov 17 17:24 libvirt.xml
[root@NFJD-PSC-IBMN-SV356 10d31bfa-961d-44ea-b554-7575315a8e2e]# qemu-img info disk
image: disk
file format: qcow2
virtual size: 40G (42949672960 bytes)
disk size: 678M
cluster_size: 65536
backing file: /var/lib/nova/instances/_base/af019e4c89c44506c068ada379c040848416510e
Format specific information:
    compat: 1.1
    lazy refcounts: false
</code></pre>
<p>ll The output of this file is more than 600 megabytes, but nova statistics are based on 40G. Because the nova code counts disk_over_committed. nova will store the statistical disk information in the table compute_nodes of the nova database and provide it to the scheduler.</p>
<p>The virtual size here minus the disk size is over_commit_size.</p>
<p>It can be seen that only the image in qcow2 format is overcommited here, and the over_commit_size of other files is equal to 0.</p>
<p>In the DiskFilter of the nova scheduling service, disk_allocation_ratio is used to over-allocate disk resources. It is not the same concept as overcommit here. It is the overuse seen from the perspective of the control node, but cannot be seen by the computing node. Overcommit is a calculation The node sees the result obtained after the disk qcow2 compression format, and the remaining space it finally reports is the actual result after deducting the hypothetical qcow2 image file decompression. Therefore, the remaining space actually reported is smaller than the space seen by the naked eye.</p>
<p>If the administrator specifies a computing node during deployment, the virtual machine will be forced to the computing node without going through the scheduling process, forcibly occupying the space that has been included in the oversubscription plan, which may eventually cause the disk resources reported by the computing node is a negative number. And in the future, as the actual disk space occupied by the virtual machine becomes larger and larger, the hard disk space of the computing node may eventually be insufficient.</p>
<h1 id="novnc-can-not-open-the-problem-location"><a class="header" href="#novnc-can-not-open-the-problem-location">novnc can not open the problem location</a></h1>
<p>Maybe the compute firewall has been changed</p>
<p>Add in /etc/sysconfig/iptables</p>
<pre><code>-A INPUT -p tcp --dport 5900:6100 -j ACCEPT
</code></pre>
<h1 id="qemu-ga-fails-to-start-because-it-cannot-find-the-corresponding-virtual-serial-character-device-prompting-that-the-channel-cannot-be-found"><a class="header" href="#qemu-ga-fails-to-start-because-it-cannot-find-the-corresponding-virtual-serial-character-device-prompting-that-the-channel-cannot-be-found">qemu-ga fails to start because it cannot find the corresponding virtual serial character device, prompting that the channel cannot be found</a></h1>
<p>glance image-update –property hw_qemu_guest_agent=yes $IMAGE_ID# … For other property configurations, be sure to set property hw_qemu_guest_agent=yes, otherwise libvert will not generate qemu-ga configuration items when starting the virtual machine, causing the qemu-ga inside the virtual machine to fail to find The corresponding virtual serial character device fails to start, prompting that the channel cannot be found.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../SUMMARY.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                            <a rel="next" href="../openstack/openstack-local-yum.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../SUMMARY.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                    <a rel="next" href="../openstack/openstack-local-yum.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="../sidebar.js"></script>
    </body>
</html>